
from functools import partial

include: "filter_fragment_file.rules"

def get_batch_signature(batch, _dir, aggregated_rule, sample_level_rule):
        
    samples = list(config['data'][batch].keys())

    if len(samples) > 1:
        return aggregated_rule.format(
            directory = _dir,
            batch = batch
        )
    else:
        return sample_level_rule.format(
            directory = _dir, 
            batch = batch, 
            sample = samples[0],
        )

def get_aggregated_intermediates(wildcards,*, aggregated_rule, sample_level_rule, debug = ''):

    if wildcards.batch == 'bulk':

        if len(config['data']) > 1:
            return aggregated_rule
        else:
            return get_batch_signature(list(config['data'].keys())[0], 
                    wildcards.directory, aggregated_rule, sample_level_rule
                )

    elif wildcards.sample == 'bulk':

        if len(config['data'][wildcards.batch]) > 1:
            return aggregated_rule
        else:
            return sample_level_rule.format(
                directory = wildcards.directory, 
                batch = wildcards.batch, 
                sample = list(config['data'][wildcards.batch].keys())[0]
            )
    else:
        return sample_level_rule


def iterate_batches_samples(wildcards,*,aggregated_rule, sample_level_rule, debug = ''):

    if wildcards.batch == 'bulk':

        return [get_batch_signature(batch, wildcards.directory, 
                        aggregated_rule, sample_level_rule)
                for batch in config['data'].keys()
            ]

    else:

        return [sample_level_rule.format(
                    directory = wildcards.directory, 
                    batch = wildcards.batch, sample = sample)
                for sample in config['data'][wildcards.batch].keys()]


rule merge_fragment_file:
    input: 
        partial(iterate_batches_samples, 
            aggregated_rule = '{directory}/bulk/fragments-merged.bed.gz',
            sample_level_rule= rules.filter_chromosomes.output[0], debug = 'merge_fragment_file')
    output:
        '{directory}/{batch}/bulk/fragments-merged.bed.gz'
    shell:
        "mira-preprocess interleave-fragments -f {input} --is-gzipped | gzip > {output}"


def get_call_peaks_input(wildcards):

    if 'filter_by_barcode' in config and config['filter_by_barcode']:
        return rules.filter_barcodes
    elif 'short_fragments' in config['peaks'] and config['peaks']['short_fragments']:
        return rules.filter_short_fragments
    else:
        if wildcards.sample == 'bulk':
            return rules.merge_fragment_file
        else:
            return rules.filter_chromosomes


rule call_peaks:
    input: 
        lambda w : get_aggregated_intermediates(w, 
            aggregated_rule = get_call_peaks_input(w).output[0],
            sample_level_rule = get_call_peaks_input(w).output[0],
            debug = 'call_peaks',
            )
    output: 
        '{directory}/{batch}/{sample}/peakcall/{batch}.{sample}_summits.bed'
    params:
        outdir = lambda w : '{directory}/{batch}/{sample}/peakcall'.format(directory = w.directory,
                batch = w.batch, sample = w.sample),
        name = lambda w : '{batch}.{sample}'.format(batch = w.batch, sample = w.sample),
        genome_size = config['peaks']['genome_size'],
    shell:
        "mira-preprocess call-peaks -i {input} -d {params.outdir} -n {params.name} "
        "-g {params.genome_size}"


rule slop_peaks:
    input : 
        rules.call_peaks.output
    output : 
        '{directory}/{batch}/{sample}/summits-slopped.bed'
    params :
        genome_file = config['genome']['chrom_sizes'],
        slop_distance = config['peaks']['slop_distance']
    shell :
        "bedtools slop -i {input} -g {params.genome_file} -b {params.slop_distance} > {output}"


def get_extra_sample_level_merges(wildcards, ):

    if not wildcards.batch == 'bulk':
        return [rules.slop_peaks.output[0].format(
                directory = wildcards.directory, batch = wildcards.batch,
                sample = 'bulk'
            )]
    else:
        return []

rule merge_peaks:
    input: 
        lambda w : iterate_batches_samples(w,
            aggregated_rule = '{directory}/{batch}/bulk/merged-peakset.bed',
            sample_level_rule = rules.slop_peaks.output[0], debug = 'merge_peaks') + \
            get_extra_sample_level_merges(w)
    output:
        '{directory}/{batch}/bulk/merged-peakset.bed'
    params:
        genome_file = config['genome']['chrom_sizes'],
        style = lambda w : 'consensus' if w.batch == 'bulk' else 'iterative-overlap'
    shell:
        "mira-preprocess merge-peaks -s {input} "
        "-g {params.genome_file} -o {output}"


rule aggregate_peakcounts:
    input : 
        peaks = partial(get_aggregated_intermediates, 
                    aggregated_rule = rules.merge_peaks.output[0], 
                    sample_level_rule = rules.slop_peaks.output[0], debug = 'aggregate_peakcounts-peaks'),
        fragments = partial(get_aggregated_intermediates, 
                    aggregated_rule = rules.merge_fragment_file.output[0], 
                    sample_level_rule = rules.filter_chromosomes.output[0], debug = 'aggregate_peakcounts-fragments'),
    output:
        '{directory}/{batch}/{sample}/peakcounts.h5ad'
    params :
        genome_file = config['genome']['chrom_sizes'],
    shell:
        "mira-preprocess agg-countmatrix --fragments {input.fragments} "
        "--peaks {input.peaks} "
        "--genome-file {params.genome_file} -o {output}"
